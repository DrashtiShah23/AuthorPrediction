{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b23858a7-8f9f-4fb7-bfcf-0f1c9a2d5bba",
    "_uuid": "125ba73bccf909bf24a1cfee0d6c0bd772d95d06"
   },
   "source": [
    "AIM:  We're challenged to predict the author of excerpts from horror stories by Edgar Allan Poe, Mary Shelley, and HP Lovecraft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "0289247b-e183-4b83-9a4a-777c1ccd2cbc",
    "_uuid": "282f761b71584453b7c57203edfcc8677d9738a0"
   },
   "outputs": [],
   "source": [
    "# We get the data:\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "df = pd.read_csv('./train.csv') # read the train csv file into the program \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d72d93c-d319-4d4e-ad04-ee0d153f7fb3",
    "_uuid": "2686ff0796119ece5ada79c8a9a3c35d323e9420"
   },
   "source": [
    "## Preprocessing and Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default top 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author\n",
       "id                                                               \n",
       "id26305  This process, however, afforded me no means of...    EAP\n",
       "id17569  It never once occurred to me that the fumbling...    HPL\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=0) #dropping the first column\n",
    "df.set_index('id', inplace = True) # set the dataframe index to id \n",
    "df.head() # default top 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag # import for pre processing and tagging\n",
    "\n",
    "def countPartOfSpeech(text, partOfSpeech):\n",
    "    text = word_tokenize(text) # tokenize\n",
    "    tags = pos_tag(text)  # tag each token to a part of speech \n",
    "\n",
    "    counter = 0 # counter to track the count of words (pos)\n",
    "    \n",
    "    if (partOfSpeech == 'adjectives'):\n",
    "        for word in tags: # loop thru tags\n",
    "            if(word[1] == 'JJ' or word[1] == 'JJR' or word[1] == 'JJS'): # tags return a tuple, so to get pos, we need to access 1 index\n",
    "                counter += 1\n",
    "                    \n",
    "    if (partOfSpeech == 'nouns'):\n",
    "        for word in tags:\n",
    "            if(word[1] == 'NN' or word[1] == 'NNS' or word[1] == 'NNPS' or word[1] == 'NNP'):  # tags return a tuple, so to get pos, we need to access 1 index\n",
    "                counter += 1          \n",
    "        \n",
    "    if (partOfSpeech == 'verbs'):\n",
    "        for word in tags:\n",
    "            if(word[1] == 'VB' or word[1] == 'VBD' or word[1] == 'VBG' or word[1] == 'VBN' or word[1] == 'VBP'or word[1] == 'VBZ'): # tags return a tuple, so to get pos, we need to access 1 index\n",
    "                counter += 1\n",
    "                \n",
    "    return counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "63e391e6-e238-454f-b93c-b2f249d16efc",
    "_uuid": "2596bb126e8ee018a6940ae31c8aa89cc0d84e8d",
    "execution": {
     "iopub.status.busy": "2022-10-27T20:19:35.634971Z",
     "iopub.status.idle": "2022-10-27T20:19:35.635396Z",
     "shell.execute_reply": "2022-10-27T20:19:35.635200Z",
     "shell.execute_reply.started": "2022-10-27T20:19:35.635182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>this process however afforded me no means of a...</td>\n",
       "      <td>224</td>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "      <td>6.380952</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>it never once occurred to me that the fumbling...</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>in his left hand was a gold snuff box from whi...</td>\n",
       "      <td>195</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>5.947368</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>how lovely is spring as we looked from windsor...</td>\n",
       "      <td>202</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>6.476190</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>finding nothing else not even gold the superin...</td>\n",
       "      <td>170</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author  \\\n",
       "id                                                                  \n",
       "id26305  This process, however, afforded me no means of...    EAP   \n",
       "id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id26305  this process however afforded me no means of a...     224     41   \n",
       "id17569  it never once occurred to me that the fumbling...      70     14   \n",
       "id11008  in his left hand was a gold snuff box from whi...     195     36   \n",
       "id27763  how lovely is spring as we looked from windsor...     202     34   \n",
       "id12958  finding nothing else not even gold the superin...     170     27   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  adjectives  nouns  verbs  \n",
       "id                                                                              \n",
       "id26305                  21         6.380952       4           2     12      6  \n",
       "id17569                   6         6.166667       0           1      2      2  \n",
       "id11008                  19         5.947368       4           5     10      4  \n",
       "id27763                  21         6.476190       3           6     10      5  \n",
       "id12958                  16         7.187500       2           1      6      6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "#creating a function to encapsulate preprocessing, to mkae it easy to replicate on  submission data\n",
    "def processing(df):\n",
    "    #lowering and removing punctuation\n",
    "    df['processed'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n",
    "#     df['tokens'] = df['processed'].apply(word_tokenize).apply(pos_tag)\n",
    "#     tags = nltk.pos_tag(tokens)\n",
    "#     df['tags'] = df['tokens'].apply(lambda x: nltk.pos_tag(x))\n",
    "    \n",
    "    #numerical feature engineering\n",
    "    #total length of sentence\n",
    "    df['length'] = df['processed'].apply(lambda x: len(x))\n",
    "    #get number of words\n",
    "    df['words'] = df['processed'].apply(lambda x: len(x.split(' ')))\n",
    "    df['words_not_stopword'] = df['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords]))\n",
    "    #get the average word length\n",
    "    df['avg_word_length'] = df['processed'].apply(lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len([len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n",
    "    #get the average word length\n",
    "    df['commas'] = df['text'].apply(lambda x: x.count(','))\n",
    "    #get the count of part of speech : adjectives\n",
    "    df['adjectives'] = df['processed'].apply(lambda word: countPartOfSpeech(word, 'adjectives'))\n",
    "    #get the count of part of speech : nouns\n",
    "    df['nouns'] = df['processed'].apply(lambda word: countPartOfSpeech(word, 'nouns'))\n",
    "    #get the count of part of speech : verbs\n",
    "    df['verbs'] = df['processed'].apply(lambda word: countPartOfSpeech(word, 'verbs'))\n",
    "                                            \n",
    "    \n",
    "#     df['nouns'] = df['processed'].apply(lambda x: nltk.pos_tag(x))\n",
    "\n",
    "\n",
    "    return(df)\n",
    "\n",
    "df = processing(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9f65b065-59e9-42ea-a76e-9a38a9e69109",
    "_uuid": "e477b8cbf9fc8a15c9f4aa13908314350caaa95b"
   },
   "source": [
    "### Creating a Pipeline\n",
    "\n",
    "First step, split your data into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "27efeecb-8feb-41c1-96d8-7bc21b452e7b",
    "_uuid": "23b0a8d116caf454325f63af4b108e74023ca8de",
    "execution": {
     "iopub.status.busy": "2022-10-27T20:19:35.636652Z",
     "iopub.status.idle": "2022-10-27T20:19:35.637225Z",
     "shell.execute_reply": "2022-10-27T20:19:35.636962Z",
     "shell.execute_reply.started": "2022-10-27T20:19:35.636924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id19417</th>\n",
       "      <td>this panorama is indeed glorious and i should ...</td>\n",
       "      <td>91</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09522</th>\n",
       "      <td>there was a simple natural earnestness about h...</td>\n",
       "      <td>240</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>6.277778</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22732</th>\n",
       "      <td>who are you pray that i duc de lomelette princ...</td>\n",
       "      <td>387</td>\n",
       "      <td>74</td>\n",
       "      <td>38</td>\n",
       "      <td>5.552632</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10351</th>\n",
       "      <td>he had gone in the carriage to the nearest tow...</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24580</th>\n",
       "      <td>there is no method in their proceedings beyond...</td>\n",
       "      <td>71</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id19417  this panorama is indeed glorious and i should ...      91     18   \n",
       "id09522  there was a simple natural earnestness about h...     240     44   \n",
       "id22732  who are you pray that i duc de lomelette princ...     387     74   \n",
       "id10351  he had gone in the carriage to the nearest tow...     118     24   \n",
       "id24580  there is no method in their proceedings beyond...      71     13   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  adjectives  nouns  verbs  \n",
       "id                                                                              \n",
       "id19417                   6         6.666667       1           1      4      2  \n",
       "id09522                  18         6.277778       4           7      8      7  \n",
       "id22732                  38         5.552632       9           3     18     10  \n",
       "id10351                  11         5.363636       0           1      8      3  \n",
       "id24580                   5         7.000000       1           0      4      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features= [c for c in df.columns.values if c  not in ['id','text','author']]\n",
    "numeric_features= [c for c in df.columns.values if c  not in ['id','text','author','processed']]\n",
    "target = 'author'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.33, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id26305    EAP\n",
       "id17569    HPL\n",
       "id11008    EAP\n",
       "id27763    MWS\n",
       "id12958    HPL\n",
       "          ... \n",
       "id17718    EAP\n",
       "id08973    EAP\n",
       "id05267    EAP\n",
       "id17513    EAP\n",
       "id00393    HPL\n",
       "Name: author, Length: 19579, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b712489b-156e-48bb-a2a2-53eac0060cc9",
    "_uuid": "74efdcc9ffe37aac7901fbb63e1a1feede3602cb"
   },
   "source": [
    "Now for the tricky parts.\n",
    "\n",
    "First thing I want to do is define how to process my variables. The standard preprocessing apply the same preprocessing to the whole dataset, but in cases where you have heterogeneous data, this doesn't quite work. So first thing I'm going to do is create a selector transformer that simply returns the one column in the dataset by the key value I pass. \n",
    "\n",
    "I was having difficulty getting the selector to play nicely, so I made two different selectors for either text or numeric columns. The return type is different, but other than that they work the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "66f0363d-1414-4d23-87fa-a0190c0f6a3a",
    "_uuid": "2d8983e1d86a9d1323b0bde3083c6fe2e2650378",
    "execution": {
     "iopub.status.busy": "2022-10-27T20:19:35.638386Z",
     "iopub.status.idle": "2022-10-27T20:19:35.638788Z",
     "shell.execute_reply": "2022-10-27T20:19:35.638628Z",
     "shell.execute_reply.started": "2022-10-27T20:19:35.638610Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "55de63e6-8d2f-478f-9126-6e7b0546207c",
    "_uuid": "2caac353c114eb6cc7e493eecfa90639cadb5e84",
    "execution": {
     "iopub.status.busy": "2022-10-27T20:19:35.639809Z",
     "iopub.status.idle": "2022-10-27T20:19:35.640159Z",
     "shell.execute_reply": "2022-10-27T20:19:35.640003Z",
     "shell.execute_reply.started": "2022-10-27T20:19:35.639987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13117x21516 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 148061 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text = Pipeline([\n",
    "                ('selector', TextSelector(key='processed')),\n",
    "                ('tfidf', TfidfVectorizer( stop_words='english'))\n",
    "            ])\n",
    "\n",
    "text.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "ea77456b-f7cc-4480-97a5-4b4c819de7a1",
    "_uuid": "eb59242f760520108b9b8f73c108f584af3130f0",
    "execution": {
     "iopub.status.busy": "2022-10-27T20:19:35.642660Z",
     "iopub.status.idle": "2022-10-27T20:19:35.644783Z",
     "shell.execute_reply": "2022-10-27T20:19:35.644521Z",
     "shell.execute_reply.started": "2022-10-27T20:19:35.644493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50769254],\n",
       "       [ 0.88000324],\n",
       "       [ 2.24907223],\n",
       "       ...,\n",
       "       [-0.46112557],\n",
       "       [-0.14447015],\n",
       "       [-0.39593181]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "length =  Pipeline([\n",
    "                ('selector', NumberSelector(key='length')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "\n",
    "length.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "71f2c594-9bd8-4d4e-bd3c-7316a604bcdf",
    "_uuid": "ec08bbc51a6226c4d725936b36243b819bd43d1a"
   },
   "source": [
    "We can see that the transformer pipeline returns a matrix for the column it's called on, so now all that's left to do is join the results from several transformed variables into a single dataset. I'll go ahead and make a pipeline for every variable in the data, then join them all together. \n",
    "\n",
    "First, I'll transform all the numeric columns with the standard scaler, but of course you can change the scaler for any column as you desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "80d80de4-bede-4cdf-8047-e3bb878c6609",
    "_uuid": "93fde50658fe3a3ce9b481d66f8ff39570a6be10",
    "execution": {
     "iopub.execute_input": "2022-10-27T20:19:35.658662Z",
     "iopub.status.busy": "2022-10-27T20:19:35.657592Z",
     "iopub.status.idle": "2022-10-27T20:19:35.677635Z",
     "shell.execute_reply": "2022-10-27T20:19:35.675736Z",
     "shell.execute_reply.started": "2022-10-27T20:19:35.658612Z"
    }
   },
   "outputs": [],
   "source": [
    "words =  Pipeline([\n",
    "                ('selector', NumberSelector(key='words')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "words_not_stopword =  Pipeline([\n",
    "                ('selector', NumberSelector(key='words_not_stopword')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "avg_word_length =  Pipeline([\n",
    "                ('selector', NumberSelector(key='avg_word_length')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "commas =  Pipeline([\n",
    "                ('selector', NumberSelector(key='commas')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "adjectives =  Pipeline([\n",
    "                ('selector', NumberSelector(key='adjectives')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "nouns =  Pipeline([\n",
    "                ('selector', NumberSelector(key='nouns')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "verbs =  Pipeline([\n",
    "                ('selector', NumberSelector(key='verbs')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "150d3ce6-9fed-4ce0-a3e9-8f955ad7874d",
    "_uuid": "2a709500025294ef8a4cfda02f7a7d02a96ff61b"
   },
   "source": [
    " Use a FeatureUnion to join the feature processing pipelines.\n",
    "\n",
    "The syntax is the same as a regular pipeline, it's just an array of tuple, with the (name, object) format. \n",
    "\n",
    "The feature union itself is not a pipeline, it's just a union, so you need to do *one more step* to make it useable: pass it to a pipeline, with the same structure, an array of tuples, with the simple (name, object) format. . As you can see, we get a pipeline-ception going on the more complex you get! \n",
    "\n",
    "You can then apply all those transformations at once with a single fit, transform, or fit_transform call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "95d16585-367f-4e74-98fd-bd266e19a672",
    "_uuid": "65f49fd19c57ba619518b2a0de615e08cb4f3c5f",
    "execution": {
     "iopub.status.busy": "2022-10-27T20:19:35.678854Z",
     "iopub.status.idle": "2022-10-27T20:19:35.679333Z",
     "shell.execute_reply": "2022-10-27T20:19:35.679146Z",
     "shell.execute_reply.started": "2022-10-27T20:19:35.679126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13117x21524 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 252997 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion([('text', text), \n",
    "                      ('length', length),\n",
    "                      ('words', words),\n",
    "                      ('words_not_stopword', words_not_stopword),\n",
    "                      ('avg_word_length', avg_word_length),\n",
    "                      ('commas', commas),\n",
    "                      ('adjectives', adjectives),\n",
    "                     ('verbs', verbs),\n",
    "                     ('nouns', nouns)])\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7e759f03-b2fd-4dcc-893e-ab00bbe0a128",
    "_uuid": "c1e3d4b661d5a48ee886ddbee613e384f9525d94"
   },
   "source": [
    "To add a model to the mix and generate predictions as well, you can add a model at the end of the pipeline. The syntax is, you guessed it, an array of tuples, merging the transformations with a model. \n",
    "\n",
    "We can see the raw accuracy is at 63%. Not bad for a start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "84b4ce5d-c4a3-46f7-903f-c4c2d7518ecd",
    "_uuid": "acaeeee80c58268f3b21d9d2c1cd7a9a3b5fcd21",
    "execution": {
     "iopub.status.busy": "2022-10-27T20:19:35.681934Z",
     "iopub.status.idle": "2022-10-27T20:19:35.683124Z",
     "shell.execute_reply": "2022-10-27T20:19:35.682855Z",
     "shell.execute_reply.started": "2022-10-27T20:19:35.682824Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7785515320334262"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logModel = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', logModel),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "preds = pipeline.predict(X_test)\n",
    "np.mean(preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9223907905771137\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify hyperparameter to tune for logistic regression\n",
    "hyperparameters = [\n",
    "    { 'classifier__penalty' : ['l2','none'],\n",
    "     'classifier__solver' : ['newton-cg', 'sag'],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'features', 'classifier', 'features__n_jobs', 'features__transformer_list', 'features__transformer_weights', 'features__verbose', 'features__text', 'features__length', 'features__words', 'features__words_not_stopword', 'features__avg_word_length', 'features__commas', 'features__adjectives', 'features__verbs', 'features__nouns', 'features__text__memory', 'features__text__steps', 'features__text__verbose', 'features__text__selector', 'features__text__tfidf', 'features__text__selector__key', 'features__text__tfidf__analyzer', 'features__text__tfidf__binary', 'features__text__tfidf__decode_error', 'features__text__tfidf__dtype', 'features__text__tfidf__encoding', 'features__text__tfidf__input', 'features__text__tfidf__lowercase', 'features__text__tfidf__max_df', 'features__text__tfidf__max_features', 'features__text__tfidf__min_df', 'features__text__tfidf__ngram_range', 'features__text__tfidf__norm', 'features__text__tfidf__preprocessor', 'features__text__tfidf__smooth_idf', 'features__text__tfidf__stop_words', 'features__text__tfidf__strip_accents', 'features__text__tfidf__sublinear_tf', 'features__text__tfidf__token_pattern', 'features__text__tfidf__tokenizer', 'features__text__tfidf__use_idf', 'features__text__tfidf__vocabulary', 'features__length__memory', 'features__length__steps', 'features__length__verbose', 'features__length__selector', 'features__length__standard', 'features__length__selector__key', 'features__length__standard__copy', 'features__length__standard__with_mean', 'features__length__standard__with_std', 'features__words__memory', 'features__words__steps', 'features__words__verbose', 'features__words__selector', 'features__words__standard', 'features__words__selector__key', 'features__words__standard__copy', 'features__words__standard__with_mean', 'features__words__standard__with_std', 'features__words_not_stopword__memory', 'features__words_not_stopword__steps', 'features__words_not_stopword__verbose', 'features__words_not_stopword__selector', 'features__words_not_stopword__standard', 'features__words_not_stopword__selector__key', 'features__words_not_stopword__standard__copy', 'features__words_not_stopword__standard__with_mean', 'features__words_not_stopword__standard__with_std', 'features__avg_word_length__memory', 'features__avg_word_length__steps', 'features__avg_word_length__verbose', 'features__avg_word_length__selector', 'features__avg_word_length__standard', 'features__avg_word_length__selector__key', 'features__avg_word_length__standard__copy', 'features__avg_word_length__standard__with_mean', 'features__avg_word_length__standard__with_std', 'features__commas__memory', 'features__commas__steps', 'features__commas__verbose', 'features__commas__selector', 'features__commas__standard', 'features__commas__selector__key', 'features__commas__standard__copy', 'features__commas__standard__with_mean', 'features__commas__standard__with_std', 'features__adjectives__memory', 'features__adjectives__steps', 'features__adjectives__verbose', 'features__adjectives__selector', 'features__adjectives__standard', 'features__adjectives__selector__key', 'features__adjectives__standard__copy', 'features__adjectives__standard__with_mean', 'features__adjectives__standard__with_std', 'features__verbs__memory', 'features__verbs__steps', 'features__verbs__verbose', 'features__verbs__selector', 'features__verbs__standard', 'features__verbs__selector__key', 'features__verbs__standard__copy', 'features__verbs__standard__with_mean', 'features__verbs__standard__with_std', 'features__nouns__memory', 'features__nouns__steps', 'features__nouns__verbose', 'features__nouns__selector', 'features__nouns__standard', 'features__nouns__selector__key', 'features__nouns__standard__copy', 'features__nouns__standard__with_mean', 'features__nouns__standard__with_std', 'classifier__C', 'classifier__class_weight', 'classifier__dual', 'classifier__fit_intercept', 'classifier__intercept_scaling', 'classifier__l1_ratio', 'classifier__max_iter', 'classifier__multi_class', 'classifier__n_jobs', 'classifier__penalty', 'classifier__random_state', 'classifier__solver', 'classifier__tol', 'classifier__verbose', 'classifier__warm_start'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV #import for grid search cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pipeline, hyperparameters, cv = 2) # specify the cv for 2 fold and hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = clf.fit(X_train, y_train) # fit the model with cv = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('text',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         TextSelector(key='processed')),\n",
       "                                                                                        ('tfidf',\n",
       "                                                                                         TfidfVectorizer(stop_words='english'))])),\n",
       "                                                                       ('length',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberSelector(key='length')),\n",
       "                                                                                        ('standard',\n",
       "                                                                                         StandardScaler())])),\n",
       "                                                                       ('words',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberS...\n",
       "                                                                                         StandardScaler())])),\n",
       "                                                                       ('verbs',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberSelector(key='verbs')),\n",
       "                                                                                        ('standard',\n",
       "                                                                                         StandardScaler())])),\n",
       "                                                                       ('nouns',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberSelector(key='nouns')),\n",
       "                                                                                        ('standard',\n",
       "                                                                                         StandardScaler())]))])),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'classifier__penalty': ['l2', 'none'],\n",
       "                          'classifier__solver': ['newton-cg', 'sag']}])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_  # display the best parameter for cv = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7793252862890746"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#refitting on entire training data using best settings\n",
    "clf.refit\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "probs = clf.predict_proba(X_test)\n",
    "\n",
    "np.mean(preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>0.239048</td>\n",
       "      <td>0.064894</td>\n",
       "      <td>0.696058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>0.830118</td>\n",
       "      <td>0.038690</td>\n",
       "      <td>0.131193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>0.236574</td>\n",
       "      <td>0.700423</td>\n",
       "      <td>0.063003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>0.696089</td>\n",
       "      <td>0.197475</td>\n",
       "      <td>0.106436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>0.684022</td>\n",
       "      <td>0.224643</td>\n",
       "      <td>0.091335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EAP       HPL       MWS\n",
       "id                                   \n",
       "id02310  0.239048  0.064894  0.696058\n",
       "id24541  0.830118  0.038690  0.131193\n",
       "id00134  0.236574  0.700423  0.063003\n",
       "id27757  0.696089  0.197475  0.106436\n",
       "id04081  0.684022  0.224643  0.091335"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on test set for the cv = 2\n",
    "submission = pd.read_csv('./test.csv')\n",
    "\n",
    "#preprocessing\n",
    "submission = processing(submission)\n",
    "predictions = clf.predict_proba(submission)\n",
    "\n",
    "preds = pd.DataFrame(data=predictions, columns = clf.best_estimator_.named_steps['classifier'].classes_)\n",
    "\n",
    "#generating a submission file\n",
    "result = pd.concat([submission[['id']], preds], axis=1)\n",
    "result.set_index('id', inplace = True)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8133, 12361, 11427], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# coefs=logModel.coef_[0]\n",
    "# feat_name = logModel.intercept_[0]\n",
    "# top_three = np.argpartition(coefs, -3)[-3:]\n",
    "# top_three\n",
    "# top_three = np.argpartition(coefs, -3)[-3:]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pipeline, hyperparameters, cv = 10) # specify the cv for 10 fold and hyper parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = clf.fit(X_train, y_train) # fit the model with cv = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_) # display the best parameter for cv = 10\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7793252862890746"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refitting on entire training data using best settings\n",
    "clf.refit\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "probs = clf.predict_proba(X_test)\n",
    "\n",
    "np.mean(preds == y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>0.239048</td>\n",
       "      <td>0.064894</td>\n",
       "      <td>0.696058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>0.830118</td>\n",
       "      <td>0.038690</td>\n",
       "      <td>0.131193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>0.236574</td>\n",
       "      <td>0.700423</td>\n",
       "      <td>0.063003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>0.696089</td>\n",
       "      <td>0.197475</td>\n",
       "      <td>0.106436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>0.684022</td>\n",
       "      <td>0.224643</td>\n",
       "      <td>0.091335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EAP       HPL       MWS\n",
       "id                                   \n",
       "id02310  0.239048  0.064894  0.696058\n",
       "id24541  0.830118  0.038690  0.131193\n",
       "id00134  0.236574  0.700423  0.063003\n",
       "id27757  0.696089  0.197475  0.106436\n",
       "id04081  0.684022  0.224643  0.091335"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on test set for the cv = 10\n",
    "submission = pd.read_csv('./test.csv')\n",
    "\n",
    "#preprocessing\n",
    "submission = processing(submission)\n",
    "predictions = clf.predict_proba(submission)\n",
    "\n",
    "preds = pd.DataFrame(data=predictions, columns = clf.best_estimator_.named_steps['classifier'].classes_)\n",
    "\n",
    "#generating a submission file\n",
    "result = pd.concat([submission[['id']], preds], axis=1)\n",
    "result.set_index('id', inplace = True)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pipeline, hyperparameters, cv = 20, verbose = 20) # specify the cv for 20 fold and hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 4 candidates, totalling 80 fits\n",
      "[CV 1/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg.......\n",
      "[CV 1/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.809 total time=   2.2s\n",
      "[CV 2/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg.......\n",
      "[CV 2/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.785 total time=   2.6s\n",
      "[CV 3/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg.......\n",
      "[CV 3/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.790 total time=   2.4s\n",
      "[CV 4/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg.......\n",
      "[CV 4/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.773 total time=   2.6s\n",
      "[CV 5/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg.......\n",
      "[CV 5/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.777 total time=   2.9s\n",
      "[CV 6/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg.......\n",
      "[CV 6/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.811 total time=   2.4s\n",
      "[CV 7/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg.......\n",
      "[CV 7/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.774 total time=   2.5s\n",
      "[CV 8/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg.......\n",
      "[CV 8/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.803 total time=   2.3s\n",
      "[CV 9/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg.......\n",
      "[CV 9/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.756 total time=   2.4s\n",
      "[CV 10/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg......\n",
      "[CV 10/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.767 total time=   3.0s\n",
      "[CV 11/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg......\n",
      "[CV 11/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.799 total time=   2.6s\n",
      "[CV 12/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg......\n",
      "[CV 12/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.777 total time=   2.4s\n",
      "[CV 13/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg......\n",
      "[CV 13/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.788 total time=   2.6s\n",
      "[CV 14/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg......\n",
      "[CV 14/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.782 total time=   2.3s\n",
      "[CV 15/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg......\n",
      "[CV 15/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.793 total time=   2.5s\n",
      "[CV 16/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg......\n",
      "[CV 16/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.803 total time=   2.5s\n",
      "[CV 17/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg......\n",
      "[CV 17/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.817 total time=   2.9s\n",
      "[CV 18/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg......\n",
      "[CV 18/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.782 total time=   2.4s\n",
      "[CV 19/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg......\n",
      "[CV 19/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.794 total time=   2.5s\n",
      "[CV 20/20; 1/4] START classifier__penalty=l2, classifier__solver=newton-cg......\n",
      "[CV 20/20; 1/4] END classifier__penalty=l2, classifier__solver=newton-cg;, score=0.776 total time=   2.4s\n",
      "[CV 1/20; 2/4] START classifier__penalty=l2, classifier__solver=sag.............\n",
      "[CV 1/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.628 total time=   1.2s\n",
      "[CV 2/20; 2/4] START classifier__penalty=l2, classifier__solver=sag.............\n",
      "[CV 2/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.585 total time=   1.1s\n",
      "[CV 3/20; 2/4] START classifier__penalty=l2, classifier__solver=sag.............\n",
      "[CV 3/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.595 total time=   1.1s\n",
      "[CV 4/20; 2/4] START classifier__penalty=l2, classifier__solver=sag.............\n",
      "[CV 4/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.596 total time=   1.3s\n",
      "[CV 5/20; 2/4] START classifier__penalty=l2, classifier__solver=sag.............\n",
      "[CV 5/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.534 total time=   1.2s\n",
      "[CV 6/20; 2/4] START classifier__penalty=l2, classifier__solver=sag.............\n",
      "[CV 6/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.607 total time=   1.1s\n",
      "[CV 7/20; 2/4] START classifier__penalty=l2, classifier__solver=sag.............\n",
      "[CV 7/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.593 total time=   1.1s\n",
      "[CV 8/20; 2/4] START classifier__penalty=l2, classifier__solver=sag.............\n",
      "[CV 8/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.694 total time=   1.2s\n",
      "[CV 9/20; 2/4] START classifier__penalty=l2, classifier__solver=sag.............\n",
      "[CV 9/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.575 total time=   1.1s\n",
      "[CV 10/20; 2/4] START classifier__penalty=l2, classifier__solver=sag............\n",
      "[CV 10/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.573 total time=   1.1s\n",
      "[CV 11/20; 2/4] START classifier__penalty=l2, classifier__solver=sag............\n",
      "[CV 11/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.599 total time=   1.1s\n",
      "[CV 12/20; 2/4] START classifier__penalty=l2, classifier__solver=sag............\n",
      "[CV 12/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.614 total time=   1.1s\n",
      "[CV 13/20; 2/4] START classifier__penalty=l2, classifier__solver=sag............\n",
      "[CV 13/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.584 total time=   1.1s\n",
      "[CV 14/20; 2/4] START classifier__penalty=l2, classifier__solver=sag............\n",
      "[CV 14/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.576 total time=   1.1s\n",
      "[CV 15/20; 2/4] START classifier__penalty=l2, classifier__solver=sag............\n",
      "[CV 15/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.608 total time=   1.1s\n",
      "[CV 16/20; 2/4] START classifier__penalty=l2, classifier__solver=sag............\n",
      "[CV 16/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.640 total time=   1.2s\n",
      "[CV 17/20; 2/4] START classifier__penalty=l2, classifier__solver=sag............\n",
      "[CV 17/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.570 total time=   1.4s\n",
      "[CV 18/20; 2/4] START classifier__penalty=l2, classifier__solver=sag............\n",
      "[CV 18/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.598 total time=   1.1s\n",
      "[CV 19/20; 2/4] START classifier__penalty=l2, classifier__solver=sag............\n",
      "[CV 19/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.618 total time=   1.2s\n",
      "[CV 20/20; 2/4] START classifier__penalty=l2, classifier__solver=sag............\n",
      "[CV 20/20; 2/4] END classifier__penalty=l2, classifier__solver=sag;, score=0.585 total time=   1.1s\n",
      "[CV 1/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg.....\n",
      "[CV 1/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.674 total time=  47.8s\n",
      "[CV 2/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg.....\n",
      "[CV 2/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.625 total time=  43.6s\n",
      "[CV 3/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg.....\n",
      "[CV 3/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.660 total time=  44.0s\n",
      "[CV 4/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg.....\n",
      "[CV 4/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.599 total time=  17.3s\n",
      "[CV 5/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.623 total time= 1.2min\n",
      "[CV 6/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg.....\n",
      "[CV 6/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.639 total time=  50.5s\n",
      "[CV 7/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg.....\n",
      "[CV 7/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.648 total time=  37.5s\n",
      "[CV 8/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg.....\n",
      "[CV 8/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.651 total time=  45.1s\n",
      "[CV 9/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg.....\n",
      "[CV 9/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.559 total time=  47.8s\n",
      "[CV 10/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg....\n",
      "[CV 10/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.578 total time=  51.2s\n",
      "[CV 11/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg....\n",
      "[CV 11/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.631 total time=  59.7s\n",
      "[CV 12/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg....\n",
      "[CV 12/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.610 total time=  46.9s\n",
      "[CV 13/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg....\n",
      "[CV 13/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.642 total time=  52.9s\n",
      "[CV 14/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg....\n",
      "[CV 14/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.630 total time=  56.2s\n",
      "[CV 15/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg....\n",
      "[CV 15/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.648 total time=  46.8s\n",
      "[CV 16/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg....\n",
      "[CV 16/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.651 total time=  41.6s\n",
      "[CV 17/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg....\n",
      "[CV 17/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.643 total time=  50.1s\n",
      "[CV 18/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg....\n",
      "[CV 18/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.602 total time=  51.1s\n",
      "[CV 19/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg....\n",
      "[CV 19/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.609 total time= 1.4min\n",
      "[CV 20/20; 3/4] START classifier__penalty=none, classifier__solver=newton-cg....\n",
      "[CV 20/20; 3/4] END classifier__penalty=none, classifier__solver=newton-cg;, score=0.614 total time=  47.1s\n",
      "[CV 1/20; 4/4] START classifier__penalty=none, classifier__solver=sag...........\n",
      "[CV 1/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.628 total time=   1.3s\n",
      "[CV 2/20; 4/4] START classifier__penalty=none, classifier__solver=sag...........\n",
      "[CV 2/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.588 total time=   1.2s\n",
      "[CV 3/20; 4/4] START classifier__penalty=none, classifier__solver=sag...........\n",
      "[CV 3/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.596 total time=   1.2s\n",
      "[CV 4/20; 4/4] START classifier__penalty=none, classifier__solver=sag...........\n",
      "[CV 4/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.598 total time=   1.2s\n",
      "[CV 5/20; 4/4] START classifier__penalty=none, classifier__solver=sag...........\n",
      "[CV 5/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.537 total time=   1.2s\n",
      "[CV 6/20; 4/4] START classifier__penalty=none, classifier__solver=sag...........\n",
      "[CV 6/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.608 total time=   1.2s\n",
      "[CV 7/20; 4/4] START classifier__penalty=none, classifier__solver=sag...........\n",
      "[CV 7/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.591 total time=   1.2s\n",
      "[CV 8/20; 4/4] START classifier__penalty=none, classifier__solver=sag...........\n",
      "[CV 8/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.704 total time=   1.2s\n",
      "[CV 9/20; 4/4] START classifier__penalty=none, classifier__solver=sag...........\n",
      "[CV 9/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.575 total time=   1.5s\n",
      "[CV 10/20; 4/4] START classifier__penalty=none, classifier__solver=sag..........\n",
      "[CV 10/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.573 total time=   1.3s\n",
      "[CV 11/20; 4/4] START classifier__penalty=none, classifier__solver=sag..........\n",
      "[CV 11/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.604 total time=   1.2s\n",
      "[CV 12/20; 4/4] START classifier__penalty=none, classifier__solver=sag..........\n",
      "[CV 12/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.617 total time=   1.2s\n",
      "[CV 13/20; 4/4] START classifier__penalty=none, classifier__solver=sag..........\n",
      "[CV 13/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.582 total time=   1.2s\n",
      "[CV 14/20; 4/4] START classifier__penalty=none, classifier__solver=sag..........\n",
      "[CV 14/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.581 total time=   1.2s\n",
      "[CV 15/20; 4/4] START classifier__penalty=none, classifier__solver=sag..........\n",
      "[CV 15/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.608 total time=   1.2s\n",
      "[CV 16/20; 4/4] START classifier__penalty=none, classifier__solver=sag..........\n",
      "[CV 16/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.643 total time=   1.2s\n",
      "[CV 17/20; 4/4] START classifier__penalty=none, classifier__solver=sag..........\n",
      "[CV 17/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.573 total time=   1.2s\n",
      "[CV 18/20; 4/4] START classifier__penalty=none, classifier__solver=sag..........\n",
      "[CV 18/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.598 total time=   1.2s\n",
      "[CV 19/20; 4/4] START classifier__penalty=none, classifier__solver=sag..........\n",
      "[CV 19/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.617 total time=   1.2s\n",
      "[CV 20/20; 4/4] START classifier__penalty=none, classifier__solver=sag..........\n",
      "[CV 20/20; 4/4] END classifier__penalty=none, classifier__solver=sag;, score=0.585 total time=   1.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('text',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         TextSelector(key='processed')),\n",
       "                                                                                        ('tfidf',\n",
       "                                                                                         TfidfVectorizer(stop_words='english'))])),\n",
       "                                                                       ('length',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberSelector(key='length')),\n",
       "                                                                                        ('standard',\n",
       "                                                                                         StandardScaler())])),\n",
       "                                                                       ('words',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         Number...\n",
       "                                                                                         StandardScaler())])),\n",
       "                                                                       ('verbs',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberSelector(key='verbs')),\n",
       "                                                                                        ('standard',\n",
       "                                                                                         StandardScaler())])),\n",
       "                                                                       ('nouns',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberSelector(key='nouns')),\n",
       "                                                                                        ('standard',\n",
       "                                                                                         StandardScaler())]))])),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'classifier__penalty': ['l2', 'none'],\n",
       "                          'classifier__solver': ['newton-cg', 'sag']}],\n",
       "             verbose=20)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with cv = 20\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_ # display the best parameter for cv = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7793252862890746"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#refitting on entire training data using best settings\n",
    "clf.refit\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "probs = clf.predict_proba(X_test)\n",
    "\n",
    "np.mean(preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>0.239048</td>\n",
       "      <td>0.064894</td>\n",
       "      <td>0.696058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>0.830118</td>\n",
       "      <td>0.038690</td>\n",
       "      <td>0.131193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>0.236574</td>\n",
       "      <td>0.700423</td>\n",
       "      <td>0.063003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>0.696089</td>\n",
       "      <td>0.197475</td>\n",
       "      <td>0.106436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>0.684022</td>\n",
       "      <td>0.224643</td>\n",
       "      <td>0.091335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EAP       HPL       MWS\n",
       "id                                   \n",
       "id02310  0.239048  0.064894  0.696058\n",
       "id24541  0.830118  0.038690  0.131193\n",
       "id00134  0.236574  0.700423  0.063003\n",
       "id27757  0.696089  0.197475  0.106436\n",
       "id04081  0.684022  0.224643  0.091335"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on test set for the cv = 20\n",
    "submission = pd.read_csv('./test.csv')\n",
    "\n",
    "#preprocessing\n",
    "submission = processing(submission)\n",
    "predictions = clf.predict_proba(submission)\n",
    "\n",
    "preds = pd.DataFrame(data=predictions, columns = clf.best_estimator_.named_steps['classifier'].classes_)\n",
    "\n",
    "#generating a submission file\n",
    "result = pd.concat([submission[['id']], preds], axis=1)\n",
    "result.set_index('id', inplace = True)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feature_analysis = X_train[numeric_features]\n",
    "# mapping the labels to 0, 1, 2 to segregate the classes\n",
    "\n",
    "y_train_feature_analysis = y_train.map({'EAP':0, 'HPL':1, 'MWS':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "newModel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newModel.fit(X_train_feature_analysis, y_train_feature_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_coef = np.absolute(newModel.coef_[0]) # take absolute value of all  feature weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'feature_n': pd.Series(X_train_feature_analysis.columns.values), 'weights': abs_coef}\n",
    "new_df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_n</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>commas</td>\n",
       "      <td>0.252792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>0.182029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>words_not_stopword</td>\n",
       "      <td>0.082888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_word_length</td>\n",
       "      <td>0.081358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nouns</td>\n",
       "      <td>0.080528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>words</td>\n",
       "      <td>0.075052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adjectives</td>\n",
       "      <td>0.063915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>length</td>\n",
       "      <td>0.001379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature_n   weights\n",
       "4              commas  0.252792\n",
       "7               verbs  0.182029\n",
       "2  words_not_stopword  0.082888\n",
       "3     avg_word_length  0.081358\n",
       "6               nouns  0.080528\n",
       "1               words  0.075052\n",
       "5          adjectives  0.063915\n",
       "0              length  0.001379"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.sort_values(by= 'weights' , axis = 0, ascending=False) # sort the feature weights in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_n</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adjectives</td>\n",
       "      <td>0.063915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nouns</td>\n",
       "      <td>0.080528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs</td>\n",
       "      <td>0.182029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_n   weights\n",
       "5  adjectives  0.063915\n",
       "6       nouns  0.080528\n",
       "7       verbs  0.182029"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[5:8] # display the weights learnt for the three features added in HW#9. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19047  2903 19048 16537 12361  8836 18515 10679 16801  5702]\n"
     ]
    }
   ],
   "source": [
    "# importance = clf.coef_\n",
    "# # summarize feature importance\n",
    "# for i,v in enumerate(importance):\n",
    "# \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "for i in range(0, logModel.coef_.shape[0]):\n",
    "    top10_indices = np.argsort(logModel.coef_[i])[:10]\n",
    "\n",
    "print(top10_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance\n",
    "# importance = newModel.coef_[0]\n",
    "# summarize feature importance\n",
    "# for i,v in enumerate(importance):\n",
    "#     print('Feature: %0d, Importance: (%.5f)' % (i,v))\n",
    "#     list.append(v)\n",
    "#     print(i)\n",
    "#     print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2162,  209,  216],\n",
       "       [ 354, 1376,  122],\n",
       "       [ 407,  123, 1493]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm #confusion matrix for 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data-points for which the model prediction is wrong\n",
    "X_test[\"actual\"] = y_test\n",
    "X_test[\"predicted\"] = preds\n",
    "\n",
    "incorrect = X_test[X_test[\"actual\"] != X_test[\"predicted\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id16303</th>\n",
       "      <td>he had seen so many customs and witnessed so g...</td>\n",
       "      <td>399</td>\n",
       "      <td>69</td>\n",
       "      <td>33</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>MWS</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14743</th>\n",
       "      <td>she listened to me as she had done to the narr...</td>\n",
       "      <td>279</td>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>6.722222</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>MWS</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07281</th>\n",
       "      <td>his chief amusements were gunning and fishing ...</td>\n",
       "      <td>214</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>7.470588</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>EAP</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id23995</th>\n",
       "      <td>i will content myself with saying in addition ...</td>\n",
       "      <td>166</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>7.083333</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>EAP</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18564</th>\n",
       "      <td>johns i bade the knocker enter but was answere...</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>HPL</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13058</th>\n",
       "      <td>at fifteen or even at twenty one for i had now...</td>\n",
       "      <td>133</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>5.461538</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>EAP</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id15700</th>\n",
       "      <td>though not as yet licenced physicians we now h...</td>\n",
       "      <td>145</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>HPL</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18277</th>\n",
       "      <td>the tide had turned and was coming in now and ...</td>\n",
       "      <td>89</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>HPL</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13971</th>\n",
       "      <td>burkes reflections on the french revolution</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>MWS</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27104</th>\n",
       "      <td>my best girl he had said relieves me from thes...</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>MWS</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id16303  he had seen so many customs and witnessed so g...     399     69   \n",
       "id14743  she listened to me as she had done to the narr...     279     56   \n",
       "id07281  his chief amusements were gunning and fishing ...     214     35   \n",
       "id23995  i will content myself with saying in addition ...     166     30   \n",
       "id18564  johns i bade the knocker enter but was answere...      70     14   \n",
       "id13058  at fifteen or even at twenty one for i had now...     133     27   \n",
       "id15700  though not as yet licenced physicians we now h...     145     25   \n",
       "id18277  the tide had turned and was coming in now and ...      89     19   \n",
       "id13971        burkes reflections on the french revolution      43      6   \n",
       "id27104  my best girl he had said relieves me from thes...      58     11   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  adjectives  nouns  \\\n",
       "id                                                                        \n",
       "id16303                  33         6.909091       1           8     17   \n",
       "id14743                  18         6.722222       5           2     10   \n",
       "id07281                  17         7.470588       2           1     11   \n",
       "id23995                  12         7.083333       5           3      9   \n",
       "id18564                   7         5.714286       2           0      6   \n",
       "id13058                  13         5.461538       1           3      5   \n",
       "id15700                  12         7.000000       2           1      4   \n",
       "id18277                   7         5.428571       1           0      3   \n",
       "id13971                   4         8.250000       0           1      3   \n",
       "id27104                   5         6.000000       2           1      3   \n",
       "\n",
       "         verbs actual predicted  \n",
       "id                               \n",
       "id16303     11    MWS       HPL  \n",
       "id14743     11    MWS       EAP  \n",
       "id07281      6    EAP       MWS  \n",
       "id23995      5    EAP       MWS  \n",
       "id18564      3    HPL       EAP  \n",
       "id13058      4    EAP       MWS  \n",
       "id15700      5    HPL       EAP  \n",
       "id18277      6    HPL       MWS  \n",
       "id13971      0    MWS       EAP  \n",
       "id27104      2    MWS       EAP  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 10 data-points for which the model prediction is wrong\n",
    "incorrect[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id16303</th>\n",
       "      <td>he had seen so many customs and witnessed so g...</td>\n",
       "      <td>399</td>\n",
       "      <td>69</td>\n",
       "      <td>33</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>MWS</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14743</th>\n",
       "      <td>she listened to me as she had done to the narr...</td>\n",
       "      <td>279</td>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>6.722222</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>MWS</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07281</th>\n",
       "      <td>his chief amusements were gunning and fishing ...</td>\n",
       "      <td>214</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>7.470588</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>EAP</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id23995</th>\n",
       "      <td>i will content myself with saying in addition ...</td>\n",
       "      <td>166</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>7.083333</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>EAP</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18564</th>\n",
       "      <td>johns i bade the knocker enter but was answere...</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>HPL</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04979</th>\n",
       "      <td>in these various brochures the aim is always s...</td>\n",
       "      <td>126</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>EAP</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id16577</th>\n",
       "      <td>at the same time that he taught me by their me...</td>\n",
       "      <td>209</td>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>6.176471</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>MWS</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id15067</th>\n",
       "      <td>alas i even now look back with disgust at my a...</td>\n",
       "      <td>131</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>6.583333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>MWS</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02639</th>\n",
       "      <td>the assassins must have escaped through the ot...</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>EAP</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17989</th>\n",
       "      <td>i demand and most solemnly i demand if in any ...</td>\n",
       "      <td>84</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>MWS</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1431 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id16303  he had seen so many customs and witnessed so g...     399     69   \n",
       "id14743  she listened to me as she had done to the narr...     279     56   \n",
       "id07281  his chief amusements were gunning and fishing ...     214     35   \n",
       "id23995  i will content myself with saying in addition ...     166     30   \n",
       "id18564  johns i bade the knocker enter but was answere...      70     14   \n",
       "...                                                    ...     ...    ...   \n",
       "id04979  in these various brochures the aim is always s...     126     21   \n",
       "id16577  at the same time that he taught me by their me...     209     41   \n",
       "id15067  alas i even now look back with disgust at my a...     131     23   \n",
       "id02639  the assassins must have escaped through the ot...      56      9   \n",
       "id17989  i demand and most solemnly i demand if in any ...      84     18   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  adjectives  nouns  \\\n",
       "id                                                                        \n",
       "id16303                  33         6.909091       1           8     17   \n",
       "id14743                  18         6.722222       5           2     10   \n",
       "id07281                  17         7.470588       2           1     11   \n",
       "id23995                  12         7.083333       5           3      9   \n",
       "id18564                   7         5.714286       2           0      6   \n",
       "...                     ...              ...     ...         ...    ...   \n",
       "id04979                  10         7.300000       0           3      5   \n",
       "id16577                  17         6.176471       2           5      9   \n",
       "id15067                  12         6.583333       2           2      7   \n",
       "id02639                   4         6.500000       0           1      2   \n",
       "id17989                   6         6.500000       1           2      6   \n",
       "\n",
       "         verbs actual predicted  \n",
       "id                               \n",
       "id16303     11    MWS       HPL  \n",
       "id14743     11    MWS       EAP  \n",
       "id07281      6    EAP       MWS  \n",
       "id23995      5    EAP       MWS  \n",
       "id18564      3    HPL       EAP  \n",
       "...        ...    ...       ...  \n",
       "id04979      4    EAP       MWS  \n",
       "id16577      6    MWS       EAP  \n",
       "id15067      2    MWS       EAP  \n",
       "id02639      2    EAP       HPL  \n",
       "id17989      1    MWS       EAP  \n",
       "\n",
       "[1431 rows x 11 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display all wrong predictions\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
